epochs: 1
batch_size: 8
learning_rate: 4e-4
weight_decay: 0.1 
train_task_name: "2k" # the maximal sequence length of the Babilong samples
test_task_name: "2k"
train_split: "qa1" # the Babilong split
test_split: "all"

save_model: false
save_model_name: "pt_qa_1"
log_experiment: false
run_name: "pre training on qa1, test on all splits"