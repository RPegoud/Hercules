experiment:
  name: "eduweb_pt"
  seed: 0
  babilong_test_batch_size: 4

  num_test_samples: 100
  max_seq_len: 2048 # maximum sequence length of training samples

  train_task_name: "2k" # the maximal sequence length of the Babilong samples
  test_task_name: "2k"
  train_splits: ~ # Babilong splits used in training
  test_splits: "all" # Babilong splits used in testing
  eval_with_generate: true # whether to evaluate the model performance with `.generate()`
  max_gen_tokens: 25 # maximum number of tokens generated for evaluation

  log_experiment: true

  run_name: "TEST|F_Llama|Babilong_all_splits"

llama:
  llama_hf_path: "meta-llama/Llama-3.2-1B"