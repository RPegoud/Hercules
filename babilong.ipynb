{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3dcb0b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hydra'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize, compose\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01momegaconf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OmegaConf\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hydra'"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "from colorama import Fore, Style\n",
    "from datasets import load_dataset\n",
    "from dotenv import dotenv_values\n",
    "from torch.utils.data import DataLoader\n",
    "# from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from hercules import MemoryLlama, log_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a86ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucabpag/Hercules/.venv/lib/python3.11/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'pre_training': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "initialize(version_base=\"1.3\", config_path=\"hercules/config\")\n",
    "cfg = compose(\"pre_training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3edf77e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "Hyperparameters:{\n",
      "    \"lmm\": {\n",
      "        \"attention_window_size\": 32,\n",
      "        \"hidden_dim\": 512,\n",
      "        \"learning_rate\": 0.0004,\n",
      "        \"max_adaptive_lr\": 0.01,\n",
      "        \"meta_memory_dim\": 16,\n",
      "        \"n_chunks\": 4,\n",
      "        \"n_hidden_layers\": 1,\n",
      "        \"num_attention_heads\": 4,\n",
      "        \"output_dim\": 128\n",
      "    },\n",
      "    \"memory_llama\": {\n",
      "        \"device_map\": \"auto\",\n",
      "        \"freeze_llama_layers\": true,\n",
      "        \"llama_hf_path\": \"meta-llama/Llama-3.2-1B\",\n",
      "        \"memory_layer_ids\": -1,\n",
      "        \"quantize\": true\n",
      "    },\n",
      "    \"train\": {\n",
      "        \"batch_size\": 8,\n",
      "        \"epochs\": 1,\n",
      "        \"outer_learning_rate\": 0.0003,\n",
      "        \"sample_size\": 512\n",
      "    }\n",
      "}\n",
      "Memory Llama:\"\n",
      "Trainable parameters: 1.984e+07\n",
      "Frozen parameters: 1.236e+09\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "OmegaConf.set_struct(cfg, False)\n",
    "cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n",
    "log_config(cfg_dict)\n",
    "cfg.memory_llama[\"token\"] = dotenv_values(\".env\")[\"HF_TOKEN\"]\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "model = MemoryLlama(neural_memory_config=cfg.lmm, **cfg.memory_llama)\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.memory_llama.llama_hf_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.to(device)\n",
    "print(f\"{Style.BRIGHT}{Fore.RED}Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e57d118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5daa0d5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hercules/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:491\u001b[39m, in \u001b[36mget_device_name\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_name\u001b[39m(device: Optional[_device_t] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    480\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[32m    481\u001b[39m \n\u001b[32m    482\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    489\u001b[39m \u001b[33;03m        str: the name of the device\u001b[39;00m\n\u001b[32m    490\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hercules/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:523\u001b[39m, in \u001b[36mget_device_properties\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_properties\u001b[39m(device: Optional[_device_t] = \u001b[38;5;28;01mNone\u001b[39;00m) -> _CudaDeviceProperties:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[32m    513\u001b[39m \n\u001b[32m    514\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    521\u001b[39m \u001b[33;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[32m    524\u001b[39m     device = _get_device_index(device, optional=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device >= device_count():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Hercules/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:310\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    306\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultiprocessing, you must use the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mspawn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m start method\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch._C, \u001b[33m\"\u001b[39m\u001b[33m_cuda_getDeviceCount\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTorch not compiled with CUDA enabled\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    313\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    314\u001b[39m     )\n",
      "\u001b[31mAssertionError\u001b[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0826d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba57a3d79774e5492fee6155f84ee5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5be1d1c86947228e21f751b6bf7a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = load_dataset(\"RMT-team/babilong-train-5k-samples\", \"2k\", split=\"qa1\")\n",
    "train_loader = DataLoader(train_ds, batch_size=1)\n",
    "total_loss = 0\n",
    "\n",
    "model, train_loader = accelerator.prepare(model, train_loader)\n",
    "\n",
    "for epoch in tqdm(range(cfg.train.epochs)):\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{cfg.train.epochs}\")\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs = batch[\"input\"]\n",
    "        questions = batch[\"question\"]\n",
    "        targets = batch[\"target\"]\n",
    "\n",
    "        prompts = tokenizer(\n",
    "            [f\"{i}, Question: {q}, Answer:\" for i, q in zip(inputs, questions)],\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        labels = tokenizer(targets, return_tensors=\"pt\")\n",
    "\n",
    "        input_ids = prompts[\"input_ids\"].to(device)\n",
    "        attention_mask = prompts[\"attention_mask\"].to(device)\n",
    "\n",
    "        # outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # batch_inputs = {\"input_ids\": batch, \"labels\": batch}\n",
    "\n",
    "        # outputs = model(**batch_inputs)\n",
    "        # loss = outputs.loss\n",
    "\n",
    "        # total_loss += loss.item()\n",
    "        # progress_bar.set_postfix({\"loss\": loss.item()})  # noqa: F821\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
